{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593aa07d-eb51-46fd-8840-c4a556c279bb",
   "metadata": {},
   "source": [
    "Capstone-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834dbf7-5a87-4ab3-987c-c708e3f9fb9e",
   "metadata": {},
   "source": [
    "FindDefault (Prediction of Credit Card fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92df8-5edf-4a51-acb5-aa789593dc1c",
   "metadata": {},
   "source": [
    "Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1454db3-f223-41cb-8a8b-368b42831a91",
   "metadata": {},
   "source": [
    "A credit card is one of the most used financial products to make online purchases and payments. Though the Credit cards can be a convenient way to manage your finances, they can also be risky. Credit card fraud is the unauthorized use of someone else's credit card or credit card information to make purchases or withdraw cash.\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. \n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "We have to build a classification model to predict whether a transaction is fraudulent or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c0aee-425b-4218-8401-d061e3dcaf8a",
   "metadata": {},
   "source": [
    "Tasks/Activities List "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e9fe8-1200-407c-b5c5-7e3d7c345cba",
   "metadata": {},
   "source": [
    "\tCollect the time series data from the CSV file linked here\n",
    "\n",
    "\tExploratory Data Analysis (EDA) \n",
    "\n",
    "\tGet the correct datatype for date.\n",
    "\n",
    "\tBalancing the data.\n",
    "\n",
    "\tFeature Engineering and feature selection.\n",
    "\n",
    "\tTrain/Test Split - Apply a sampling distribution to find the best split\n",
    "\n",
    "\tChoose the metrics for the model evaluation\n",
    "\n",
    "\tModel Selection, Training, Predicting and Assessment \n",
    "\n",
    "\tHyperparameter Tuning/Model Improvement \n",
    "\n",
    "\tModel deployment plan. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fef50f84-f078-4d8f-bedb-7da082bc2fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Load Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# EDA analysis \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import show\n",
    "from matplotlib.colors import ListedColormap\n",
    "#from plotnine import *\n",
    "import matplotlib.pyplot as Pyplot\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import shapiro\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,validation_curve, StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn import over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad139ce-a93b-496b-a06c-19baf8d234ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.warn('foo', DeprecationWarning)\n",
    "import warnings, sklearn.utils\n",
    "warnings.warn('bar', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33c621-1f1f-496b-afda-86fa0d7c83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will create the seperator for better data visualization among each variables\n",
    "def Line_Separator():\n",
    "    print('*'*50, '\\n')\n",
    "    \n",
    "def Line_Separator1():\n",
    "    print('*'*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d94301-9363-45fe-ba30-cb240dd17464",
   "metadata": {},
   "source": [
    "Read The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34b2e5-6b2d-4472-b4ae-5518eaf8c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard = pd.read_csv('creditcard csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1e871-0a00-4c31-9e9c-0389db8ec743",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc16753-43d3-4d98-bdf9-547f6b45aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate number of columns and rows in given dataset\n",
    "\n",
    "Number_of_row = creditcard.shape[0]\n",
    "Number_of_column = creditcard.shape[1]\n",
    "\n",
    "print('Number of rows in creditcard file     :', Number_of_row)\n",
    "print('Number of columns in creditcard file  :', Number_of_column); Line_Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df415de4-3019-43c9-a178-a14857226c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review columns title in given dataset\n",
    "\n",
    "print(\"Columns name in  creditcard file :\\n\",creditcard.columns.values);Line_Separator1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b3875-1558-41cd-b48a-224c336a8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate number of categorical and numerical features\n",
    "\n",
    "def data_features (data):\n",
    "    categorical_features = creditcard.select_dtypes(exclude = [np.number]).columns\n",
    "    numerical_features = creditcard.select_dtypes(include = [np.number]).columns\n",
    "    print(\"Categorical features in  creditcard file :\\n\",categorical_features);Line_Separator1()\n",
    "    print(\"Numerical features in  creditcard file   :\\n\",numerical_features);Line_Separator1()\n",
    "    \n",
    "print(data_features(creditcard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01147e02-aeae-404f-bfa9-e2b48c1f034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the datatypes\n",
    "print(\"Review the Data Format in  creditcard file :\");Line_Separator()\n",
    "print(creditcard.dtypes);Line_Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e380b-ecc9-48bb-8256-28a144ddc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing value if any\n",
    "\n",
    "print(\"Check if there is any missing value in in  creditcard file :\");Line_Separator()\n",
    "print(round(100*(creditcard.isnull()).sum()/len(creditcard),2).sort_values(ascending=False));Line_Separator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea13798-f616-4056-9f9e-527d311be36d",
   "metadata": {},
   "source": [
    "We are check Missing values, but i have not find any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8559dda-3151-4a0b-b51d-351050d0fe3e",
   "metadata": {},
   "source": [
    "check summary statistics credit card time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758733d-837f-472c-ae8d-3deed2d02913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time variable statistics\");Line_Separator()\n",
    "creditcard['Time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357d742-b7f3-47e2-ba01-4ff9cf47202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is 48hours, and the values seems to represent the second will convert it to hours - 1hour =3600seconds \n",
    "\n",
    "creditcard['Time'] =creditcard['Time']/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ff29e-cae0-4be1-9d9e-c45cba64ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment of classes one and zero for visualization \n",
    "\n",
    "def replace_data_to_binary(x,y):\n",
    "    creditcard.Class.replace(x,y, inplace=True)\n",
    "  \n",
    "    \n",
    "replace_data_to_binary(0, 'Non Fraudulent')\n",
    "replace_data_to_binary(1, 'Fraudulent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64cfb8-6421-49cd-ac3e-dd4a152f0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readmitted distribution\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "total = float(len(creditcard)) \n",
    "ax = sns.countplot(x=\"Class\",  data=creditcard)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of observations', fontsize=14)\n",
    "plt.title('Distrinution of Class', fontsize =14)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2., height + 3, '{:1.2f}'.format(100*height/total), \n",
    "            ha=\"center\",va='bottom')\n",
    "ax.grid(False)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.show();Line_Separator1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcc94e-3551-40c7-8050-833e232f7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate whether data is balanced or not \n",
    "\n",
    "total_count_combined_calss = creditcard['Class'].value_counts()\n",
    "imbalance= (total_count_combined_calss['Fraudulent']/creditcard['Class'].count()*100)/(total_count_combined_calss['Non Fraudulent']/creditcard['Class'].count()*100)*100\n",
    "print('Imbalance Percentage : ' + str(imbalance));Line_Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee485d9-a370-4c92-96b4-77f5bb69ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Time vs Amount scatter plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=creditcard, x='Time', y='Amount', hue='Class', palette='viridis', alpha=0.6)\n",
    "plt.title('Time vs Amount Scatter Plot')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amount')\n",
    "plt.legend(title='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e6762-9447-4331-8777-059c3fab8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amount details of fraudulent transactions:\"); Line_Separator()\n",
    "print(creditcard[creditcard[\"Class\"] == \"Fraudulent\"].Amount.describe()); Line_Separator1()\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Amount details of non-fraudulent transactions:\"); Line_Separator()\n",
    "print(creditcard[creditcard[\"Class\"] == \"Non Fraudulent\"].Amount.describe()); Line_Separator1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304ad4e-54d9-459e-bba5-6e0f7ef666d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the time vs. amount transaction between fraudulent and non-fraudulent\n",
    "\n",
    "print(\"Evaluate the time vs. amount transaction between fraudulent and non-fraudulent\");Line_Separator1()\n",
    "ax=sns.relplot(x=\"Time\", y=\"Amount\",\n",
    "                 col=\"Class\", hue=\"Class\",\n",
    "                 kind=\"scatter\", data=creditcard)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.show(); Line_Separator1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653186d-dea0-4498-ba36-66ef078fe80a",
   "metadata": {},
   "source": [
    "Few insights on the visualization above reveal the following:\n",
    "\n",
    "The plot indicates that the fraud amounts were less than approx 2.2k.\n",
    "Fraud pattern indicates that the number of data points is observed between 14 to 20 hours on both days.\n",
    "We can see a two-picks pattern in time due tonight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f010d-dd93-4cdc-b40b-82d533446852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To assign back the values 'Non Fraudulent' and 'Fraudulent' back to 0 and 1 in the Class\n",
    "def replace_data_to_binary(x, y):\n",
    "    creditcard['Class'].replace(x, y, inplace=True)\n",
    "\n",
    "# Replace 'Non Fraudulent' with 0 and 'Fraudulent' with 1\n",
    "replace_data_to_binary('Non Fraudulent', 0)\n",
    "replace_data_to_binary('Fraudulent', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e104c5e-a609-432b-893d-3a81cb73edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After reassigning class to zero and one, we will evaluate the data type \");Line_Separator1()\n",
    "print(creditcard.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16e40c-c12f-4241-b518-460e14872822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "correlation_matrix = creditcard.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ab9e4-f555-4a14-9b44-f98b5fcb2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the data distributions of each variable\n",
    "\n",
    "print(); Line_Separator1()\n",
    "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V1 to V12\"); Line_Separator1()\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "\n",
    "plt.subplot(431)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V1'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V1'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V1\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(432)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V2'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V2'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V2\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(433)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V3'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V3'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V3\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(434)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V4'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V4'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V4\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(435)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V5'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V5'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V5\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(436)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V6'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V6'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V6\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(437)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V7'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V7'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V7\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(438)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V8'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V8'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V8\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(439)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V9'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V9'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V9\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(4,3,10)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V10'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V10'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V10\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(4,3,11)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V11'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V11'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V11\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.subplot(4,3,12)\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0),'V12'] , color='b',shade=True,label='Non Fraudulent')\n",
    "g=sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1),'V12'] , color='orange',shade=True, label='Fraudulent')\n",
    "g.grid(False)\n",
    "plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "plt.xlabel(\"V12\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.show(); Line_Separator1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea434e00-0c01-45a1-a077-012b8e5ab0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(); Line_Separator1()\n",
    "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V13 to V24\"); Line_Separator1()\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "\n",
    "variables = ['V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24']\n",
    "colors = ['b', 'orange']\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0), var], color=colors[0], shade=True, label='Non Fraudulent')\n",
    "    sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1), var], color=colors[1], shade=True, label='Fraudulent')\n",
    "    plt.grid(False)\n",
    "    plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "    plt.xlabel(var, fontsize=12)\n",
    "    plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.show(); Line_Separator1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f75e0-91ed-420c-a4a9-83aa0f846405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(); Line_Separator1()\n",
    "print(\"Plotting the Shape of a Distribution of each Variable in 'Non-Fraudulent' & 'Fraudulent': Variables V25 to V28, Time & Amount\"); Line_Separator1()\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "\n",
    "# List of variables to plot\n",
    "variables = ['V25', 'V26', 'V27', 'V28', 'Time', 'Amount']\n",
    "colors = ['b', 'orange']\n",
    "\n",
    "# Plot each variable in a subplot\n",
    "for i, var in enumerate(variables):\n",
    "    plt.subplot(4, 3, i + 1)\n",
    "    sns.kdeplot(creditcard.loc[(creditcard[\"Class\"] == 0), var], color=colors[0], shade=True, label='Non Fraudulent')\n",
    "    sns.kdeplot(creditcard.loc[(creditcard['Class'] == 1), var], color=colors[1], shade=True, label='Fraudulent')\n",
    "    plt.grid(False)\n",
    "    plt.ylabel(\"Frequency Density\", fontsize=12)\n",
    "    plt.xlabel(var, fontsize=12)\n",
    "    plt.tick_params(labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show(); Line_Separator1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2573a9-627a-4fda-bd3d-a6ee155f3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Histograms of the features\n",
    "creditcard.hist(figsize=(20, 20), bins=50)\n",
    "plt.suptitle('Histograms of All Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee546c5-c046-4d71-b794-9728a11c1e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data of Non-Fraudulent and Fraudulent to check the skewness and kurtosis\n",
    "\n",
    "Non_Fraudulent= creditcard[creditcard[\"Class\"] == 0]\n",
    "print (\"Non_Fraudulent:\", Non_Fraudulent.shape); Line_Separator()\n",
    "Fraudulent= creditcard[creditcard[\"Class\"] == 1]\n",
    "print (\"Fraudulent:\", Fraudulent.shape); Line_Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1b1dc-728e-4093-a4cb-8f17bb7ba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non_Fraudulent = to check the skewness and kurtosis.\n",
    "\n",
    "print (\"Non_Fraudulent = To evaluate Mean, Variance, skewness, and kurtosis:\")\n",
    "print(\"\")\n",
    "a = Non_Fraudulent.mean(axis = 0, skipna = True)\n",
    "b = Non_Fraudulent.var(axis = 0, skipna = True)\n",
    "c = Non_Fraudulent.skew(axis = 0, skipna = True)\n",
    "d = Non_Fraudulent.kurtosis(axis = 0, skipna = True)\n",
    "\n",
    "a.index = b.index\n",
    "a.index = c.index\n",
    "a.index = d.index\n",
    "\n",
    "data_Non_Fraudulent = pd.concat([a, b, c, d] ,axis = 1)\n",
    "data_Non_Fraudulent.columns = [\"Mean\", \"Var\", \"Skewness\", \"kurtosis\"]\n",
    "data_Non_Fraudulent=data_Non_Fraudulent.reset_index().rename(index=str, columns={\"index\": \"Variables\"})\n",
    "print(data_Non_Fraudulent); Line_Separator1()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Fraudulent = to check the skewness and kurtosis\n",
    "\n",
    "print (\"Fraudulent = To evaluate Mean, Variance, skewness, and kurtosis:\")\n",
    "print(\"\")\n",
    "e = Fraudulent.mean(axis = 0, skipna = True)\n",
    "f = Fraudulent.var(axis = 0, skipna = True)\n",
    "g = Fraudulent.skew(axis = 0, skipna = True)\n",
    "h = Fraudulent.kurtosis(axis = 0, skipna = True)\n",
    "\n",
    "e.index = f.index\n",
    "e.index = g.index\n",
    "e.index = h.index\n",
    "\n",
    "data_Fraudulent = pd.concat([a, b, c, d] ,axis = 1)\n",
    "data_Fraudulent.columns = [\"Mean\", \"Var\", \"Skewness\", \"kurtosis\"]\n",
    "data_Fraudulent=data_Fraudulent.reset_index().rename(index=str, columns={\"index\": \"Variables\"})\n",
    "print(data_Fraudulent); Line_Separator1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ea464-778e-4661-97a8-5a6b6f8bfbb0",
   "metadata": {},
   "source": [
    "1.Skewness = 0 : normally distributed. ; a zero value means that the tails on both sides of the mean balance out overall,\n",
    "2.Skewness > 0: more weight in the left tail of the distribution.\n",
    "3.Skewness < 0: more weight in the right tail of the distribution.\n",
    "For example, a zero value means that the tails on both sides of the mean balance out overall; this is the case for asymmetric distribution, but it can also be true for an asymmetric distribution where one tail is long and thin, and the other is short but fat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61358922-cdcc-4480-bb75-b64b45143504",
   "metadata": {},
   "source": [
    "Note: we will look into this if we require any power transformation to the data. However, they are PCA transformed (not an original one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95984b-db6d-4c60-a91b-117dc5f925e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Fraudulent: Evaluate the number of positive skewness variables \n",
    "\n",
    "print('Non Fraudulent - Positive skewness:')\n",
    "left_skewness_Non_Fraudulent= data_Non_Fraudulent[data_Non_Fraudulent.Skewness >0]\n",
    "print(left_skewness_Non_Fraudulent['Variables'].unique());Line_Separator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafa4d3-c5af-4bd9-8519-6a72c5e8f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraudulent : Evaluate the number of positive skewness variables\n",
    "\n",
    "print('Fraudulent - Positive skewness:')\n",
    "left_skewness_Fraudulent = data_Fraudulent[data_Fraudulent.Skewness >0]\n",
    "print(left_skewness_Fraudulent['Variables'].unique());Line_Separator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdc50c-6ab2-4ba7-9b53-9d01ac0c2bef",
   "metadata": {},
   "source": [
    "Positive Skew: Mean > median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99195f4-e109-4736-aa25-95a1d96eb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Fraudulent: Evaluate the number of negative skewness variables \n",
    "print('Non Fraudulent - Negative skewness:')\n",
    "right_skewness_Non_Fraudulent= data_Non_Fraudulent[data_Non_Fraudulent.Skewness <0]\n",
    "print(right_skewness_Non_Fraudulent['Variables'].unique());Line_Separator()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# Fraudulent: Evaluate the number of negative skewness variables \n",
    "print('Fraudulent - Negative skewness:')\n",
    "right_skewness_Fraudulent = data_Fraudulent[data_Fraudulent.Skewness <0]\n",
    "print(right_skewness_Fraudulent['Variables'].unique());Line_Separator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbca0e-4d8c-4563-971e-9e8f3f40bec0",
   "metadata": {},
   "source": [
    "Negative Skew: Median > mean\n",
    "Zero Skew: Mean = median (normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dece57f-8c8a-4642-9e6f-c8a194f052f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop the time column\n",
    "\n",
    "creditcard = creditcard.drop(['Time'],axis=1)\n",
    "creditcard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a211b5-9279-4192-bfb8-65c16014ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "creditcard['Amount'] = StandardScaler().fit_transform(creditcard['Amount'].values.reshape(-1,1)) \n",
    "#creditcard['Time'] = StandardScaler().fit_transform(creditcard['Time'].values.reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0fe1b-289d-45e1-bdbd-8740e5f58916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "\n",
    "X = creditcard.drop('Class',axis=1)\n",
    "y = creditcard['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd923f-407a-4302-b3d1-4d1f3d6b077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the X dataset\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8710a-5ddb-4658-8cd2-8ffa25aca413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data shape\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59380b-380a-4fd1-bd91-f04c4cf51954",
   "metadata": {},
   "source": [
    "Splitting the dataset to Train and Test¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419571f-5326-4bf0-b077-4568a2b25c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3,train_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a3831-9adb-4522-b2c8-1b9140803e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9413c5c-96ae-45c0-ae99-712788a027b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Apply power transformation using 'yeo-johnson' method\n",
    "creditcard_pt = PowerTransformer(method='yeo-johnson', copy=True)\n",
    "creditcard_pt.fit(X_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_pt = creditcard_pt.transform(X_train)\n",
    "X_test_pt = creditcard_pt.transform(X_test)\n",
    "\n",
    "# Assign y_train to y_train_pt (No transformation needed for target variable)\n",
    "y_train_pt = y_train\n",
    "\n",
    "# Check the transformed data\n",
    "print(\"Transformed X_train:\")\n",
    "print(X_train_pt)\n",
    "print(\"\\nTransformed X_test:\")\n",
    "print(X_test_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cab4b-c428-4998-8fc2-9acd51643bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the x_train and x_test\n",
    "\n",
    "X_train = X_train_pt\n",
    "X_test = X_test_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0dfa7-6adf-42b2-9c48-d5f32d3a697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "# Apply ADASYN oversampling\n",
    "adasyn = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "X_ada, y_ada = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the resampled dataset shape\n",
    "print('Resampled dataset shape %s' % Counter(y_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb85d7-4fb8-4f82-a5f2-14fe97ce2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset after balancing it\n",
    "print(X_ada.shape)\n",
    "print(y_ada.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bac9ce-c443-43f1-bb41-0595761f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute unique data in y_ada\n",
    "\n",
    "y_ada.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ac00d-a423-40c4-87ee-fa06b25a7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "# Apply ADASYN oversampling\n",
    "adasyn = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "X_ada, y_ada = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the resampled dataset shape\n",
    "print('Resampled dataset shape %s' % Counter(y_ada))\n",
    "\n",
    "# Evaluate whether the dataset is balanced\n",
    "total_count_combined_class = y_ada.value_counts()\n",
    "imbalance = (total_count_combined_class[1] / y_ada.count() * 100) / (total_count_combined_class[0] / y_ada.count() * 100) * 100\n",
    "\n",
    "print('Balance Percentage after ADASYN: ' + str(imbalance) + '%')\n",
    "Line_Separator1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335b95f-24fc-4f47-a182-9598f05ba7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the sum of y_ada, y_train and y_test\n",
    "\n",
    "print(np.sum(y_ada))\n",
    "print(np.sum(y_train))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046e883-eb4e-4fc2-a1cc-27c4ceb63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename X_ada and y_ada\n",
    "\n",
    "X_train = X_ada\n",
    "y_train = y_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edc436-c1ad-4134-9169-be7e6ecd9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the shape of the training and test dataset after balancing it\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0345c6c-e956-4052-a976-027ff776d2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f5a4c60-54f5-4aba-8f1b-66246fc09f29",
   "metadata": {},
   "source": [
    "Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d991b-f19c-49fb-9306-8c212f8ddd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model for evaluation\n",
    "\n",
    "b_m=[]\n",
    "\n",
    "for i in range (y_test.shape[0]):\n",
    "    b_m.append(y_test.mode()[0])\n",
    "\n",
    "len(b_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c79c4a-ebf4-4571-95c2-788e41ef11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.Series(b_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbf8d2-5fa2-4e38-abb6-a70c686521cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (Base Model):', accuracy_score(y_test, y_pred)*100);Line_Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf66d2-b2e5-417a-b8e8-f68526ef44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b0821-77d8-48e0-aa45-e39fc9ce588a",
   "metadata": {},
   "source": [
    "Model Selection and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067b43f-8509-4729-aa72-7bdefb0708a8",
   "metadata": {},
   "source": [
    "We will use Logistic Regression, K-Nearest Neighbors, Decision Tree, and XGBoost as our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874305ba-ab6f-4857-a653-8248f70ca99e",
   "metadata": {},
   "source": [
    "1. Let's Create Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a093ba-cc35-4162-8055-dfc6a366f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34675917-b016-47c6-b60f-52b6aabfeb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Validation\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "evaluate_model(lr, X_test_pt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c67d0d-0a5d-45a4-9116-29ec976e8bf1",
   "metadata": {},
   "source": [
    "2.Let's Create KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0f06f-928b-4d91-819e-4aff26a145e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc5809-ca18-4172-befd-3ad66c4fa81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Validation\n",
    "print(\"K-Nearest Neighbors Evaluation:\")\n",
    "evaluate_model(knn, X_test_pt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586486a-72ee-40ca-a0dd-2481071f1720",
   "metadata": {},
   "source": [
    "3.Lets Create DecisionTreeClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d8e95-a5ff-47a3-b826-50950629c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc66535-ab74-4b95-b8a8-888ff307de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Validation\n",
    "print(\"Decision Tree Evaluation:\")\n",
    "evaluate_model(dt, X_test_pt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679aff45-7909-41ac-b0b9-d40fd2c92a19",
   "metadata": {},
   "source": [
    "4.Let's Create XGBClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6449c-7633-4d78-98c4-a07eb804de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e2edc-6e99-4b3a-ad0c-e3b10f4ebb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Validation\n",
    "print(\"XGBoost Evaluation:\")\n",
    "evaluate_model(xgb, X_test_pt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b59574-c541-4a10-b39a-f5be48bee994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa465b3-c307-460d-ab33-f328d7196db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "def get_model_metrics(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    return f1, accuracy, auc_roc, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7049c5-0893-46d1-b3e5-4a562558f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model, storing the results\n",
    "model_summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    f1, accuracy, auc_roc, precision, recall = get_model_metrics(model, X_test_pt, y_test)\n",
    "    model_summary.append([name, f1, accuracy, auc_roc, precision, recall])\n",
    "\n",
    "# Create a DataFrame for model summary\n",
    "model_summary_df = pd.DataFrame(model_summary, columns=['Name', 'F1_score', 'Accuracy', 'AUC_ROC', 'Precision', 'Recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d378256-eb1d-4d12-8f09-2c3229b463a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary_df = model_summary_df.reset_index(drop=True)\n",
    "display(model_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b273d-3714-4277-b884-bade0f4c35d3",
   "metadata": {},
   "source": [
    "All Model Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9362f84-8bc1-4af0-84d7-2c6549785360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and Classification Reports\n",
    "# Logistic Regression\n",
    "print(\"Logistic Regression - Classification Report\")\n",
    "print(classification_report(y_test, lr.predict(X_test_pt)))\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "print(\"K-Nearest Neighbors - Classification Report\")\n",
    "print(classification_report(y_test, knn.predict(X_test_pt)))\n",
    "\n",
    "# Decision Tree\n",
    "print(\"Decision Tree Evaluation - Classification Report\")\n",
    "print(classification_report(y_test, dt.predict(X_test_pt)))\n",
    "\n",
    "# XGBoost\n",
    "print(\"XGBoost - Classification Report\")\n",
    "print(classification_report(y_test, xgb.predict(X_test_pt)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255251a-72c7-4b83-969e-7c406402d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "# Logistic Regression\n",
    "lr_pred = lr.predict(X_test_pt)\n",
    "lr_cm = confusion_matrix(y_test, lr_pred)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_pred = knn.predict(X_test_pt)\n",
    "knn_cm = confusion_matrix(y_test, knn_pred)\n",
    "\n",
    "# DT\n",
    "dt_pred = dt.predict(X_test_pt)\n",
    "dt_cm = confusion_matrix(y_test, dt_pred)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pred = xgb.predict(X_test_pt)\n",
    "xgb_cm = confusion_matrix(y_test, xgb_pred)\n",
    "\n",
    "# Plotting confusion matrices\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 5))\n",
    "fig.suptitle('Confusion Matrices', fontsize=16)\n",
    "\n",
    "# Logistic Regression\n",
    "sns.heatmap(lr_cm, annot=True, cmap='Blues', fmt='d', cbar=False, ax=axes[0])\n",
    "axes[0].set_title('Logistic Regression')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "sns.heatmap(knn_cm, annot=True, cmap='Blues', fmt='d', cbar=False, ax=axes[1])\n",
    "axes[1].set_title('K-Nearest Neighbors')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "#dt\n",
    "sns.heatmap(dt_cm, annot=True, cmap='Blues', fmt='d', cbar=False, ax=axes[2])\n",
    "axes[2].set_title('Decision Tree')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('True')\n",
    "\n",
    "# XGBoost\n",
    "sns.heatmap(xgb_cm, annot=True, cmap='Blues', fmt='d', cbar=False, ax=axes[3])\n",
    "axes[3].set_title('XGBoost')\n",
    "axes[3].set_xlabel('Predicted')\n",
    "axes[3].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a027e-688b-497d-b201-2fc5e59b27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have computed confusion matrices: lr_cm, knn_cm, xgb_cm\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(cm):\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    \n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    PPV = TP / (TP + FP)\n",
    "    NPV = TN / (TN + FN)\n",
    "    \n",
    "    return sensitivity, specificity, FPR, PPV, NPV\n",
    "\n",
    "# Calculate metrics for Logistic Regression\n",
    "lr_sensitivity, lr_specificity, lr_fpr, lr_ppv, lr_npv = calculate_metrics(lr_cm)\n",
    "\n",
    "# Calculate metrics for K-Nearest Neighbors\n",
    "knn_sensitivity, knn_specificity, knn_fpr, knn_ppv, knn_npv = calculate_metrics(knn_cm)\n",
    "\n",
    "# Calculate metrics for Decision Tree\n",
    "dt_sensitivity, dt_specificity, dt_fpr, dt_ppv, dt_npv = calculate_metrics(dt_cm)\n",
    "\n",
    "# Calculate metrics for XGBoost\n",
    "xgb_sensitivity, xgb_specificity, xgb_fpr, xgb_ppv, xgb_npv = calculate_metrics(xgb_cm)\n",
    "\n",
    "# Print metrics for each model\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(f\"Sensitivity: {lr_sensitivity:.4f}, Specificity: {lr_specificity:.4f}, FPR: {lr_fpr:.4f}, PPV: {lr_ppv:.4f}, NPV: {lr_npv:.4f}\")\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Metrics:\")\n",
    "print(f\"Sensitivity: {knn_sensitivity:.4f}, Specificity: {knn_specificity:.4f}, FPR: {knn_fpr:.4f}, PPV: {knn_ppv:.4f}, NPV: {knn_npv:.4f}\")\n",
    "\n",
    "print(\"\\nDecision Tree Metrics:\")\n",
    "print(f\"Sensitivity: {dt_sensitivity:.4f}, Specificity: {dt_specificity:.4f}, FPR: {dt_fpr:.4f}, PPV: {dt_ppv:.4f}, NPV: {dt_npv:.4f}\")\n",
    "\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(f\"Sensitivity: {xgb_sensitivity:.4f}, Specificity: {xgb_specificity:.4f}, FPR: {xgb_fpr:.4f}, PPV: {xgb_ppv:.4f}, NPV: {xgb_npv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ea682-31cb-47a0-b34e-11e56163d4de",
   "metadata": {},
   "source": [
    "# ROC - Curves for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361bfd9-5bfb-4d4e-8dae-9c947367cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit models\n",
    "lr.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for ROC curve\n",
    "lr_probs = lr.predict_proba(X_test)[:, 1]\n",
    "knn_probs = knn.predict_proba(X_test)[:, 1]\n",
    "xgb_probs = xgb.predict_proba(X_test)[:, 1]\n",
    "dt_probs = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "lr_roc_auc = auc(lr_fpr, lr_tpr)\n",
    "\n",
    "knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_probs)\n",
    "knn_roc_auc = auc(knn_fpr, knn_tpr)\n",
    "\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)\n",
    "xgb_roc_auc = auc(xgb_fpr, xgb_tpr)\n",
    "\n",
    "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_probs)\n",
    "dt_roc_auc = auc(dt_fpr, dt_tpr)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(lr_fpr, lr_tpr, color='blue', lw=2, label=f'LR ROC curve (area = {lr_roc_auc:.2f})')\n",
    "plt.plot(knn_fpr, knn_tpr, color='green', lw=2, label=f'KNN ROC curve (area = {knn_roc_auc:.2f})')\n",
    "plt.plot(xgb_fpr, xgb_tpr, color='red', lw=2, label=f'XGB ROC curve (area = {xgb_roc_auc:.2f})')\n",
    "plt.plot(dt_fpr, dt_tpr, color='purple', lw=2, label=f'DT ROC curve (area = {dt_roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7428d1-7ec6-4bc7-997d-c139a36dcd51",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea515872-28e5-4def-8018-2610f5cc2e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_seldection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid_lr, cv=5, scoring='roc_auc')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "print(\"Best parameters for Logistic Regression:\", grid_lr.best_params_)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "print(\"Tuned Logistic Regression Evaluation:\")\n",
    "evaluate_model(best_lr, X_test_pt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a549ef-6134-48f8-89c1-e10b4fd34f9e",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f7cc8-afdb-4ca3-8e9d-d2d9bfcb8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "dt_grid_search = GridSearchCV(estimator=dt, param_grid=dt_param_grid, \n",
    "                              cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "print(f\"Best Parameters for Decision Tree: {dt_grid_search.best_params_}\")\n",
    "print(f\"Best Score for Decision Tree: {dt_grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "dt_best_pred = best_dt.predict(X_test_pt)\n",
    "print(classification_report(y_test, dt_best_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba185a0b-59ab-44f0-abf6-8f4a249b823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22059440-eec8-482a-91d8-f61fc4c45996",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db68cf6-3f9c-4797-9661-895ff82b0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7, 1.0],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, \n",
    "                               cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_xgb = xgb_grid_search.best_estimator_\n",
    "print(f\"Best Parameters for XGBoost: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Best Score for XGBoost: {xgb_grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "xgb_best_pred = best_xgb.predict(X_test_pt)\n",
    "print(classification_report(y_test, xgb_best_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d5e54-9892-479e-90f2-1f32cd8f0e40",
   "metadata": {},
   "source": [
    "Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9d32e-3bfe-4615-906b-423fb5f09ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_xgb, 'best_xgb_model.pkl')\n",
    "joblib.dump(best_dt, 'best_dt_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63bb8c-5361-461b-85a7-f85a195fa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_xgb, 'best_xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a9a49-682e-4453-aac6-8c2956176b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_xgb = joblib.load('best_xgb_model.pkl')\n",
    "loaded_dt = joblib.load('best_dt_model.pkl')\n",
    "\n",
    "# Make predictions\n",
    "new_predictions_xgb = loaded_xgb.predict(X_test)\n",
    "new_predictions_dt = loaded_dt.predict(X_test)\n",
    "\n",
    "# Evaluate loaded models\n",
    "print(\"Loaded XGBoost Model Evaluation:\")\n",
    "evaluate_model(loaded_xgb, X_test, y_test)\n",
    "\n",
    "print(\"\\nLoaded Decision Tree Model Evaluation:\")\n",
    "evaluate_model(loaded_dt, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dc153-519b-4ff9-9779-8a10b50f0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6df53d-fc11-4585-92e9-eeb6811c3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf650be0-fc20-447c-a9f7-3a1fcca1cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('best_xgb_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746239f4-21d7-4362-8cc8-c64b613f7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on, load the model from the file\n",
    "with open('best_xgb_model.pkl', 'rb') as file:\n",
    "    best_xgb = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db72b8e-5eb0-46b6-b605-8123c060de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded model to make predictions\n",
    "preds = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb56902-a624-4bb8-8fc6-de5a77d99816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ad3fd-9a27-4a91-98f7-0675221f6c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4567c-d938-486b-bf2f-fd316c9e63d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da460c7-496e-4146-8602-f97bba719f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212fe7f-38cd-4e41-92ee-7f28730c88ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
